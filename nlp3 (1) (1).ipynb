{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP2DAw-w371E",
        "outputId": "2a3051b7-341d-4378-f0b4-8655da23928b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gutenberg corpus first 20 words:\n",
            "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich']\n",
            "Lexical Analysis of Gutenberg corpus first 20 words:\n",
            "[('[', 'NNS'), ('Emma', 'NNP'), ('by', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), (']', 'NNP'), ('VOLUME', 'NNP'), ('I', 'PRP'), ('CHAPTER', 'VBP'), ('I', 'PRP'), ('Emma', 'NNP'), ('Woodhouse', 'NNP'), (',', ','), ('handsome', 'NN'), (',', ','), ('clever', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ')]\n",
            "\n",
            "Brown corpus first 20 words:\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n",
            "Lexical Analysis of Brown corpus first 20 words:\n",
            "[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), ('Atlanta', 'NNP'), (\"'s\", 'POS'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), ('``', '``'), ('that', 'IN')]\n",
            "\n",
            "Inaugural corpus first 20 words:\n",
            "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':', 'Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no']\n",
            "Lexical Analysis of Inaugural corpus first 20 words:\n",
            "[('Fellow', 'NNP'), ('-', ':'), ('Citizens', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Senate', 'NNP'), ('and', 'CC'), ('of', 'IN'), ('the', 'DT'), ('House', 'NNP'), ('of', 'IN'), ('Representatives', 'NNPS'), (':', ':'), ('Among', 'IN'), ('the', 'DT'), ('vicissitudes', 'NNS'), ('incident', 'NN'), ('to', 'TO'), ('life', 'NN'), ('no', 'DT')]\n",
            "\n",
            "Reuters corpus first 20 words:\n",
            "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.']\n",
            "Lexical Analysis of Reuters corpus first 20 words:\n",
            "[('ASIAN', 'NNP'), ('EXPORTERS', 'NNP'), ('FEAR', 'NNP'), ('DAMAGE', 'NNP'), ('FROM', 'NNP'), ('U', 'NNP'), ('.', '.'), ('S', 'NNP'), ('.-', 'JJ'), ('JAPAN', 'NNP'), ('RIFT', 'NNP'), ('Mounting', 'NNP'), ('trade', 'NN'), ('friction', 'NN'), ('between', 'IN'), ('the', 'DT'), ('U', 'NNP'), ('.', '.'), ('S', 'NNP'), ('.', '.')]\n",
            "\n",
            "WebText corpus first 20 words:\n",
            "['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', 'allow', 'sites', 'that', 'set', 'removed', 'cookies', 'to', 'set', 'future', 'cookies', '\"', 'should', 'stay']\n",
            "Lexical Analysis of WebText corpus first 20 words:\n",
            "[('Cookie', 'NNP'), ('Manager', 'NNP'), (':', ':'), ('``', '``'), ('Don', 'NNP'), (\"'\", 'POS'), ('t', 'NN'), ('allow', 'VB'), ('sites', 'NNS'), ('that', 'WDT'), ('set', 'VBP'), ('removed', 'VBN'), ('cookies', 'NNS'), ('to', 'TO'), ('set', 'VB'), ('future', 'JJ'), ('cookies', 'NNS'), ('``', '``'), ('should', 'MD'), ('stay', 'VB')]\n",
            "\n",
            "Brown corpus 'news' category first 20 words:\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n",
            "Lexical Analysis of Brown corpus 'news' category first 20 words:\n",
            "[('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN'), ('Atlanta', 'NNP'), (\"'s\", 'POS'), ('recent', 'JJ'), ('primary', 'JJ'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'DT'), ('evidence', 'NN'), ('``', '``'), ('that', 'IN')]\n",
            "\n",
            "Reuters corpus 'grain' category first 20 words:\n",
            "['CHINA', 'DAILY', 'SAYS', 'VERMIN', 'EAT', '7', '-', '12', 'PCT', 'GRAIN', 'STOCKS', 'A', 'survey', 'of', '19', 'provinces', 'and', 'seven', 'cities', 'showed']\n",
            "Lexical Analysis of Reuters corpus 'grain' category first 20 words:\n",
            "[('CHINA', 'NNP'), ('DAILY', 'NNP'), ('SAYS', 'NNP'), ('VERMIN', 'NNP'), ('EAT', 'NNP'), ('7', 'CD'), ('-', ':'), ('12', 'CD'), ('PCT', 'NNP'), ('GRAIN', 'NNP'), ('STOCKS', 'NNP'), ('A', 'NNP'), ('survey', 'NN'), ('of', 'IN'), ('19', 'CD'), ('provinces', 'NNS'), ('and', 'CC'), ('seven', 'CD'), ('cities', 'NNS'), ('showed', 'VBD')]\n",
            "\n",
            "WordNet first 20 synsets:\n",
            "able.a.01 (usually followed by `to') having the necessary means or skill or know-how or authority to do something\n",
            "unable.a.01 (usually followed by `to') not having the necessary means or skill or know-how\n",
            "abaxial.a.01 facing away from the axis of an organ or organism\n",
            "adaxial.a.01 nearest to or facing toward the axis of an organ or organism\n",
            "acroscopic.a.01 facing or on the side toward the apex\n",
            "basiscopic.a.01 facing or on the side toward the base\n",
            "abducent.a.01 especially of muscles; drawing away from the midline of the body or from an adjacent part\n",
            "adducent.a.01 especially of muscles; bringing together or drawing toward the midline of the body or toward an adjacent part\n",
            "nascent.a.01 being born or beginning\n",
            "emergent.s.02 coming into existence\n",
            "dissilient.s.01 bursting open with force, as do some ripe seed vessels\n",
            "parturient.s.02 giving birth\n",
            "dying.a.01 in or associated with the process of passing from life or ceasing to be\n",
            "moribund.s.02 being on the point of death; breathing your last\n",
            "last.s.05 occurring at the time of death\n",
            "abridged.a.01 (used of texts) shortened by condensing or rewriting\n",
            "cut.s.03 with parts removed\n",
            "half-length.s.02 abridged to half its original length\n",
            "potted.s.03 (British informal) summarized or abridged\n",
            "unabridged.a.01 (used of texts) not shortened\n",
            "\n",
            "Lexical Analysis of WordNet definitions first words:\n",
            "[('(', '('), ('usually', 'RB'), ('(', '('), ('usually', 'RB'), ('facing', 'VBG'), ('nearest', 'JJS'), ('facing', 'VBG'), ('facing', 'VBG'), ('especially', 'RB'), ('especially', 'RB'), ('being', 'VBG'), ('coming', 'VBG'), ('bursting', 'VBG'), ('giving', 'VBG'), ('in', 'IN'), ('being', 'VBG'), ('occurring', 'VBG'), ('(', '('), ('used', 'VBN'), ('with', 'IN'), ('abridged', 'JJ'), ('(', '('), ('British', 'JJ'), ('(', '('), ('used', 'VBN')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg, brown, inaugural, reuters, webtext, wordnet\n",
        "\n",
        "# Download the necessary NLTK data files\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('brown')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('reuters')\n",
        "nltk.download('webtext')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')  # Download additional WordNet data\n",
        "\n",
        "# Function to get the first 20 words of a corpus\n",
        "def get_first_20_words(corpus):\n",
        "    words = corpus.words()\n",
        "    return words[:20]\n",
        "\n",
        "# Function to get the first 20 words of a specific category in a corpus\n",
        "def get_first_20_words_of_category(corpus, category):\n",
        "    if corpus == brown:\n",
        "        words = brown.words(categories=category)\n",
        "    elif corpus == reuters:\n",
        "        words = reuters.words(categories=category)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported corpus or category.\")\n",
        "    return words[:20]\n",
        "\n",
        "# Function to perform lexical analysis\n",
        "def lexical_analysis(words):\n",
        "    # Tokenization\n",
        "    tokens = nltk.word_tokenize(\" \".join(words))\n",
        "    # POS tagging\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    return pos_tags\n",
        "\n",
        "# Gutenberg corpus\n",
        "gutenberg_words = get_first_20_words(gutenberg)\n",
        "print(\"Gutenberg corpus first 20 words:\")\n",
        "print(gutenberg_words)\n",
        "print(\"Lexical Analysis of Gutenberg corpus first 20 words:\")\n",
        "print(lexical_analysis(gutenberg_words))\n",
        "\n",
        "# Brown corpus\n",
        "brown_words = get_first_20_words(brown)\n",
        "print(\"\\nBrown corpus first 20 words:\")\n",
        "print(brown_words)\n",
        "print(\"Lexical Analysis of Brown corpus first 20 words:\")\n",
        "print(lexical_analysis(brown_words))\n",
        "\n",
        "# Inaugural corpus\n",
        "inaugural_words = get_first_20_words(inaugural)\n",
        "print(\"\\nInaugural corpus first 20 words:\")\n",
        "print(inaugural_words)\n",
        "print(\"Lexical Analysis of Inaugural corpus first 20 words:\")\n",
        "print(lexical_analysis(inaugural_words))\n",
        "\n",
        "# Reuters corpus\n",
        "reuters_words = get_first_20_words(reuters)\n",
        "print(\"\\nReuters corpus first 20 words:\")\n",
        "print(reuters_words)\n",
        "print(\"Lexical Analysis of Reuters corpus first 20 words:\")\n",
        "print(lexical_analysis(reuters_words))\n",
        "\n",
        "# WebText corpus\n",
        "webtext_words = get_first_20_words(webtext)\n",
        "print(\"\\nWebText corpus first 20 words:\")\n",
        "print(webtext_words)\n",
        "print(\"Lexical Analysis of WebText corpus first 20 words:\")\n",
        "print(lexical_analysis(webtext_words))\n",
        "\n",
        "# Accessing specific categories\n",
        "# Example categories: 'news' for Brown corpus, 'grain' for Reuters corpus\n",
        "brown_news_words = get_first_20_words_of_category(brown, 'news')\n",
        "print(\"\\nBrown corpus 'news' category first 20 words:\")\n",
        "print(brown_news_words)\n",
        "print(\"Lexical Analysis of Brown corpus 'news' category first 20 words:\")\n",
        "print(lexical_analysis(brown_news_words))\n",
        "\n",
        "reuters_grain_words = get_first_20_words_of_category(reuters, 'grain')\n",
        "print(\"\\nReuters corpus 'grain' category first 20 words:\")\n",
        "print(reuters_grain_words)\n",
        "print(\"Lexical Analysis of Reuters corpus 'grain' category first 20 words:\")\n",
        "print(lexical_analysis(reuters_grain_words))\n",
        "\n",
        "# Accessing WordNet\n",
        "def get_first_20_synsets():\n",
        "    synsets = list(wordnet.all_synsets())\n",
        "    return synsets[:20]\n",
        "\n",
        "wordnet_synsets = get_first_20_synsets()\n",
        "print(\"\\nWordNet first 20 synsets:\")\n",
        "for synset in wordnet_synsets:\n",
        "    print(synset.name(), synset.definition())\n",
        "\n",
        "# Example of lexical analysis with WordNet definitions\n",
        "wordnet_words = [synset.definition().split()[0] for synset in wordnet_synsets if synset.definition()]\n",
        "print(\"\\nLexical Analysis of WordNet definitions first words:\")\n",
        "print(lexical_analysis(wordnet_words))"
      ]
    }
  ]
}