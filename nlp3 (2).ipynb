{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP2DAw-w371E",
        "outputId": "05221eb8-68fd-418f-d812-512af48f4d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gutenberg corpus first 20 words:\n",
            "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich']\n",
            "\n",
            "Brown corpus first 20 words:\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n",
            "\n",
            "Inaugural corpus first 20 words:\n",
            "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':', 'Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no']\n",
            "\n",
            "Reuters corpus first 20 words:\n",
            "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.']\n",
            "\n",
            "WebText corpus first 20 words:\n",
            "['Cookie', 'Manager', ':', '\"', 'Don', \"'\", 't', 'allow', 'sites', 'that', 'set', 'removed', 'cookies', 'to', 'set', 'future', 'cookies', '\"', 'should', 'stay']\n",
            "\n",
            "Brown corpus 'news' category first 20 words:\n",
            "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that']\n",
            "\n",
            "Reuters corpus 'grain' category first 20 words:\n",
            "['CHINA', 'DAILY', 'SAYS', 'VERMIN', 'EAT', '7', '-', '12', 'PCT', 'GRAIN', 'STOCKS', 'A', 'survey', 'of', '19', 'provinces', 'and', 'seven', 'cities', 'showed']\n",
            "\n",
            "WordNet first 20 synsets:\n",
            "able.a.01 (usually followed by `to') having the necessary means or skill or know-how or authority to do something\n",
            "unable.a.01 (usually followed by `to') not having the necessary means or skill or know-how\n",
            "abaxial.a.01 facing away from the axis of an organ or organism\n",
            "adaxial.a.01 nearest to or facing toward the axis of an organ or organism\n",
            "acroscopic.a.01 facing or on the side toward the apex\n",
            "basiscopic.a.01 facing or on the side toward the base\n",
            "abducent.a.01 especially of muscles; drawing away from the midline of the body or from an adjacent part\n",
            "adducent.a.01 especially of muscles; bringing together or drawing toward the midline of the body or toward an adjacent part\n",
            "nascent.a.01 being born or beginning\n",
            "emergent.s.02 coming into existence\n",
            "dissilient.s.01 bursting open with force, as do some ripe seed vessels\n",
            "parturient.s.02 giving birth\n",
            "dying.a.01 in or associated with the process of passing from life or ceasing to be\n",
            "moribund.s.02 being on the point of death; breathing your last\n",
            "last.s.05 occurring at the time of death\n",
            "abridged.a.01 (used of texts) shortened by condensing or rewriting\n",
            "cut.s.03 with parts removed\n",
            "half-length.s.02 abridged to half its original length\n",
            "potted.s.03 (British informal) summarized or abridged\n",
            "unabridged.a.01 (used of texts) not shortened\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg, brown, inaugural, reuters, webtext, wordnet\n",
        "\n",
        "# Download the necessary NLTK data files\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('brown')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('reuters')\n",
        "nltk.download('webtext')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # Download additional WordNet data\n",
        "\n",
        "# Function to get the first 20 words of a corpus\n",
        "def get_first_20_words(corpus):\n",
        "    words = corpus.words()\n",
        "    return words[:20]\n",
        "\n",
        "# Function to get the first 20 words of a specific category in a corpus\n",
        "def get_first_20_words_of_category(corpus, category):\n",
        "    if corpus == brown:\n",
        "        words = brown.words(categories=category)\n",
        "    elif corpus == reuters:\n",
        "        words = reuters.words(categories=category)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported corpus or category.\")\n",
        "    return words[:20]\n",
        "\n",
        "# Gutenberg corpus\n",
        "gutenberg_words = get_first_20_words(gutenberg)\n",
        "print(\"Gutenberg corpus first 20 words:\")\n",
        "print(gutenberg_words)\n",
        "\n",
        "# Brown corpus\n",
        "brown_words = get_first_20_words(brown)\n",
        "print(\"\\nBrown corpus first 20 words:\")\n",
        "print(brown_words)\n",
        "\n",
        "# Inaugural corpus\n",
        "inaugural_words = get_first_20_words(inaugural)\n",
        "print(\"\\nInaugural corpus first 20 words:\")\n",
        "print(inaugural_words)\n",
        "\n",
        "# Reuters corpus\n",
        "reuters_words = get_first_20_words(reuters)\n",
        "print(\"\\nReuters corpus first 20 words:\")\n",
        "print(reuters_words)\n",
        "\n",
        "# WebText corpus\n",
        "webtext_words = get_first_20_words(webtext)\n",
        "print(\"\\nWebText corpus first 20 words:\")\n",
        "print(webtext_words)\n",
        "\n",
        "# Accessing specific categories\n",
        "# Example categories: 'news' for Brown corpus, 'grain' for Reuters corpus\n",
        "brown_news_words = get_first_20_words_of_category(brown, 'news')\n",
        "print(\"\\nBrown corpus 'news' category first 20 words:\")\n",
        "print(brown_news_words)\n",
        "\n",
        "reuters_grain_words = get_first_20_words_of_category(reuters, 'grain')\n",
        "print(\"\\nReuters corpus 'grain' category first 20 words:\")\n",
        "print(reuters_grain_words)\n",
        "\n",
        "# Accessing WordNet\n",
        "def get_first_20_synsets():\n",
        "    synsets = list(wordnet.all_synsets())\n",
        "    return synsets[:20]\n",
        "\n",
        "wordnet_synsets = get_first_20_synsets()\n",
        "print(\"\\nWordNet first 20 synsets:\")\n",
        "for synset in wordnet_synsets:\n",
        "    print(synset.name(), synset.definition())\n"
      ]
    }
  ]
}